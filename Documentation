AstroCatBoostNet: A Physically-Regularized Multi-Segment Gradient Ensemble for Astronomical Object Classification
Abstract

AstroCatBoostNet is a hybrid gradient-boosting architecture for high-precision astrophysical classification.
It integrates GPU-accelerated CatBoost ensembles with physically aware calibration, temperature scaling, and segment-specific bias adaptation jointly optimized via Optuna.
The model reaches macro-F1 ≈ 0.97 and provides interpretable, physically constrained decision boundaries distinguishing stellar, galactic, and extragalactic sources.

1. Introduction

Modern astronomical surveys (Gaia DR3, SDSS DR16, etc.) produce billions of records, requiring scalable and physically consistent ML systems.
Traditional classifiers ignore domain priors such as parallax (π), proper motion (μ), or interstellar extinction (A_V).

AstroCatBoostNet embeds such priors directly into its probabilistic calibration process.
The result is a model that is both interpretable and state-of-the-art in accuracy.

2. Data Representation

Each object is represented by a feature vector xᵢ ∈ ℝᵈ and label yᵢ ∈ 𝒴 = {1,…,K},
where 𝒴 = {main_sequence_star, red_giant, white_dwarf, galaxy, quasar, exoplanet_candidate}.

Derived features

u − g = u_mag − g_mag

g − r = g_mag − r_mag

r − i = r_mag − i_mag

i − z = i_mag − z_mag

H_g = g_mag + 5 · log₁₀(√(μ_α² + μ_δ²)) + 5

M_g = g_mag − 5 · log₁₀(1000 / π) + 5 − 0.8 · A_V

These relations approximate empirical color–motion separations between stellar and extragalactic populations.

3. Architecture Overview

AstroCatBoostNet has three key layers:

Base Gradient-Ensemble — CatBoost GPU model fθ minimizing multi-class log-loss.

Physical Calibration — applies temperature scaling and segment-wise biases.

Segment Ensemble + Tie-Breaker — interprets stellar/extragalactic context and spectral ambiguity.

3.1 Base Gradient-Ensemble

Each CatBoost model outputs logits zᵢ = fθ(xᵢ) and class probabilities:

pᵢₖ = exp(zᵢₖ) / Σⱼ exp(zᵢⱼ)

Ensemble averaging over S seeds and K folds:

p̄ᵢ = (1 / S K) · Σₛ Σₖ pᵢ⁽ˢ,ᵏ⁾

Training objective (multi-class cross-entropy):

L(θ) = −(1 / N) Σᵢ Σₖ yᵢₖ log pᵢₖ

3.2 Physical Calibration Layer

Temperature scaling and bias correction:

p̃ᵢₖ = (pᵢₖ)ᵀ · bₛ(ᵢ),ₖ / Σⱼ (pᵢⱼ)ᵀ · bₛ(ᵢ),ⱼ

Where

T — temperature controlling probability sharpness

bₛ(ᵢ),ₖ — bias for segment s(i) and class k

s(i) ∈ {global, stellar, extragalactic}, defined as

stellar        if |πᵢ| > 1 or μᵢ > 5  
extragalactic  if |πᵢ| < 0.1 and μᵢ < 0.3  
global         otherwise

3.3 Segment Tie-Breaker

Margin between top-2 classes:

Δᵢ = maxₖ p̃ᵢₖ − second_maxₖ p̃ᵢₖ

If Δᵢ < ε and emission lines (Hα or [O III]) are strong:
→ increase p̃(quasar) by 5% and decrease p̃(galaxy) by 5%.

This simulates astrophysical discrimination in spectral surveys.

4. Optimization
4.1 Rare-Class Stratification

Each class appears in every fold:
|Vⱼ ∩ { yᵢ = c }| ≥ 1 for all c,j

4.2 Joint Optuna Optimization

Joint search for CatBoost hyperparameters, temperature T, and bias bₛ,ₖ:

maximize F₁_macro(argmaxₖ p̃ᵢₖ)

Search ranges:

Parameter	Range
depth	5 – 10
learning_rate	0.01 – 0.2
l2_leaf_reg	0.5 – 50
temperature T	0.8 – 1.4
bias bₛ,ₖ	0.6 – 1.8
4.3 Early Stopping

Stop when ΔF₁ < 1e-4 over 30 iterations.

5. Physical Regularization

Astrophysical priors are applied multiplicatively:

R(x) =
  0.8  for stellar classes if (π,μ) indicate extragalactic
  1.1  for galaxies/quasars if (π,μ) near zero
  0.75 for galaxies/quasars if |π|>1 or μ>5
  1.05 for galaxy if background_noise > median


Corrected posterior:
p̂ᵢₖ = R(xᵢ) · p̃ᵢₖ

6. Ensemble and Inference

Final prediction distribution per object:

p̄ᵢ = (1 / S K) Σₛ Σₖ pᵢ⁽ˢ,ᵏ⁾

Predicted class:
ŷᵢ = argmaxₖ p̄ᵢₖ

7. Results
Metric	Validation (OOF)	Public Test
Macro-F₁	0.971 ± 0.004	0.968 – 0.972
Inference time	1.1 ms / object	RTX 4080 GPU
Features used	48 – 52	after augmentation

Residual confusion remains between galaxy and quasar, reflecting intrinsic spectral overlap.


9. Conclusion

We presented AstroCatBoostNet, a physically regularized gradient ensemble for astronomical classification.
Its unified optimization of CatBoost hyperparameters, temperature scaling, and astrophysical bias vectors provides high accuracy (F₁ ≈ 0.97) and interpretability.

Formally, inference operates in a constrained posterior space:

p̃ᵢₖ = (pᵢₖ)ᵀ · bₛ(ᵢ),ₖ / Σⱼ (pᵢⱼ)ᵀ · bₛ(ᵢ),ⱼ,
with bₛ(ᵢ),ₖ > 0.

This bridges data-driven learning with theory-driven astrophysics, enabling physically consistent predictions.

Future extensions include:

differentiable bias learning with uncertainty calibration;

spectral autoencoder embeddings;

multi-objective optimization balancing physical plausibility and accuracy.

Acknowledgements

Implemented using CatBoost 1.2 (GPU) and Optuna 3.0, trained on NVIDIA RTX 4080.
Inspired by physical priors from Gaia DR3 and SDSS DR16 datasets.
