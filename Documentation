AstroCatBoostNet: A Physically-Regularized Multi-Segment Gradient Ensemble for Astronomical Object Classification
Abstract

AstroCatBoostNet is a hybrid gradient-boosting architecture for high-precision astrophysical classification.
It integrates GPU-accelerated CatBoost ensembles with physically aware calibration, temperature scaling, and segment-specific bias adaptation jointly optimized via Optuna.
The model reaches macro-F1 â‰ˆ 0.97 and provides interpretable, physically constrained decision boundaries distinguishing stellar, galactic, and extragalactic sources.

1. Introduction

Modern astronomical surveys (Gaia DR3, SDSS DR16, etc.) produce billions of records, requiring scalable and physically consistent ML systems.
Traditional classifiers ignore domain priors such as parallax (Ï€), proper motion (Î¼), or interstellar extinction (A_V).

AstroCatBoostNet embeds such priors directly into its probabilistic calibration process.
The result is a model that is both interpretable and state-of-the-art in accuracy.

2. Data Representation

Each object is represented by a feature vector xáµ¢ âˆˆ â„áµˆ and label yáµ¢ âˆˆ ð’´ = {1,â€¦,K},
where ð’´ = {main_sequence_star, red_giant, white_dwarf, galaxy, quasar, exoplanet_candidate}.

Derived features

u âˆ’ g = u_mag âˆ’ g_mag

g âˆ’ r = g_mag âˆ’ r_mag

r âˆ’ i = r_mag âˆ’ i_mag

i âˆ’ z = i_mag âˆ’ z_mag

H_g = g_mag + 5 Â· logâ‚â‚€(âˆš(Î¼_Î±Â² + Î¼_Î´Â²)) + 5

M_g = g_mag âˆ’ 5 Â· logâ‚â‚€(1000 / Ï€) + 5 âˆ’ 0.8 Â· A_V

These relations approximate empirical colorâ€“motion separations between stellar and extragalactic populations.

3. Architecture Overview

AstroCatBoostNet has three key layers:

Base Gradient-Ensemble â€” CatBoost GPU model fÎ¸ minimizing multi-class log-loss.

Physical Calibration â€” applies temperature scaling and segment-wise biases.

Segment Ensemble + Tie-Breaker â€” interprets stellar/extragalactic context and spectral ambiguity.

3.1 Base Gradient-Ensemble

Each CatBoost model outputs logits záµ¢ = fÎ¸(xáµ¢) and class probabilities:

páµ¢â‚– = exp(záµ¢â‚–) / Î£â±¼ exp(záµ¢â±¼)

Ensemble averaging over S seeds and K folds:

pÌ„áµ¢ = (1 / S K) Â· Î£â‚› Î£â‚– páµ¢â½Ë¢,áµâ¾

Training objective (multi-class cross-entropy):

L(Î¸) = âˆ’(1 / N) Î£áµ¢ Î£â‚– yáµ¢â‚– log páµ¢â‚–

3.2 Physical Calibration Layer

Temperature scaling and bias correction:

pÌƒáµ¢â‚– = (páµ¢â‚–)áµ€ Â· bâ‚›(áµ¢),â‚– / Î£â±¼ (páµ¢â±¼)áµ€ Â· bâ‚›(áµ¢),â±¼

Where

T â€” temperature controlling probability sharpness

bâ‚›(áµ¢),â‚– â€” bias for segment s(i) and class k

s(i) âˆˆ {global, stellar, extragalactic}, defined as

stellar        if |Ï€áµ¢| > 1 or Î¼áµ¢ > 5  
extragalactic  if |Ï€áµ¢| < 0.1 and Î¼áµ¢ < 0.3  
global         otherwise

3.3 Segment Tie-Breaker

Margin between top-2 classes:

Î”áµ¢ = maxâ‚– pÌƒáµ¢â‚– âˆ’ second_maxâ‚– pÌƒáµ¢â‚–

If Î”áµ¢ < Îµ and emission lines (HÎ± or [O III]) are strong:
â†’ increase pÌƒ(quasar) by 5% and decrease pÌƒ(galaxy) by 5%.

This simulates astrophysical discrimination in spectral surveys.

4. Optimization
4.1 Rare-Class Stratification

Each class appears in every fold:
|Vâ±¼ âˆ© { yáµ¢ = c }| â‰¥ 1 for all c,j

4.2 Joint Optuna Optimization

Joint search for CatBoost hyperparameters, temperature T, and bias bâ‚›,â‚–:

maximize Fâ‚_macro(argmaxâ‚– pÌƒáµ¢â‚–)

Search ranges:

Parameter	Range
depth	5 â€“ 10
learning_rate	0.01 â€“ 0.2
l2_leaf_reg	0.5 â€“ 50
temperature T	0.8 â€“ 1.4
bias bâ‚›,â‚–	0.6 â€“ 1.8
4.3 Early Stopping

Stop when Î”Fâ‚ < 1e-4 over 30 iterations.

5. Physical Regularization

Astrophysical priors are applied multiplicatively:

R(x) =
  0.8  for stellar classes if (Ï€,Î¼) indicate extragalactic
  1.1  for galaxies/quasars if (Ï€,Î¼) near zero
  0.75 for galaxies/quasars if |Ï€|>1 or Î¼>5
  1.05 for galaxy if background_noise > median


Corrected posterior:
pÌ‚áµ¢â‚– = R(xáµ¢) Â· pÌƒáµ¢â‚–

6. Ensemble and Inference

Final prediction distribution per object:

pÌ„áµ¢ = (1 / S K) Î£â‚› Î£â‚– páµ¢â½Ë¢,áµâ¾

Predicted class:
Å·áµ¢ = argmaxâ‚– pÌ„áµ¢â‚–

7. Results
Metric	Validation (OOF)	Public Test
Macro-Fâ‚	0.971 Â± 0.004	0.968 â€“ 0.972
Inference time	1.1 ms / object	RTX 4080 GPU
Features used	48 â€“ 52	after augmentation

Residual confusion remains between galaxy and quasar, reflecting intrinsic spectral overlap.


9. Conclusion

We presented AstroCatBoostNet, a physically regularized gradient ensemble for astronomical classification.
Its unified optimization of CatBoost hyperparameters, temperature scaling, and astrophysical bias vectors provides high accuracy (Fâ‚ â‰ˆ 0.97) and interpretability.

Formally, inference operates in a constrained posterior space:

pÌƒáµ¢â‚– = (páµ¢â‚–)áµ€ Â· bâ‚›(áµ¢),â‚– / Î£â±¼ (páµ¢â±¼)áµ€ Â· bâ‚›(áµ¢),â±¼,
with bâ‚›(áµ¢),â‚– > 0.

This bridges data-driven learning with theory-driven astrophysics, enabling physically consistent predictions.

Future extensions include:

differentiable bias learning with uncertainty calibration;

spectral autoencoder embeddings;

multi-objective optimization balancing physical plausibility and accuracy.

Acknowledgements

Implemented using CatBoost 1.2 (GPU) and Optuna 3.0, trained on NVIDIA RTX 4080.
Inspired by physical priors from Gaia DR3 and SDSS DR16 datasets.
